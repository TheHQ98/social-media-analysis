{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9cb883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from shapely.geometry import Point\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f061908",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch(\n",
    "    \"https://elastic:elastic@127.0.0.1:9200\",\n",
    "    verify_certs=False,  # 测试环境可临时关闭证书校验\n",
    "    ssl_show_warn=False,\n",
    "    basic_auth=(\"elastic\", \"elastic\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1546959d",
   "metadata": {},
   "source": [
    "# Australian Politics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827db934",
   "metadata": {},
   "outputs": [],
   "source": [
    "election_keywords = [\n",
    "    # General election terms\n",
    "    \"election\", \"vote\", \"ballot\", \"polling\", \"campaign\", \"candidate\", \"political party\",\n",
    "    \"preference\", \"electorate\", \"constituency\", \"seat\", \"margin\", \"swing\", \"democracy\",\n",
    "    \n",
    "    # Australian political parties\n",
    "    \"liberal party\", \"labor party\", \"alp\", \"lnp\", \"nationals\", \"greens\", \"one nation\",\n",
    "    \"united australia party\", \"uap\", \"independents\", \"coalition\", \"teals\", \n",
    "    \n",
    "    # Political figures\n",
    "    \"prime minister\", \"anthony albanese\", \"albo\", \"scott morrison\", \"peter dutton\", \n",
    "    \"adam bandt\", \"pauline hanson\", \"clive palmer\", \"bob katter\", \"jacqui lambie\",\n",
    "    \n",
    "    # Policy issues\n",
    "    \"climate change\", \"housing\", \"cost of living\", \"economy\", \"taxation\", \"healthcare\", \n",
    "    \"medicare\", \"education\", \"immigration\", \"refugees\", \"indigenous\", \"first nations\",\n",
    "    \"aboriginal\", \"defence\", \"aukus\", \"infrastructure\", \"corruption\", \"integrity\",\n",
    "    \n",
    "    # Electoral authorities\n",
    "    \"aec\", \"australian electoral commission\", \"preferential voting\", \"compulsory voting\",\n",
    "    \"electoral roll\", \"senate\", \"house of representatives\", \"parliament\", \"hung parliament\",\n",
    "    \n",
    "    # Election events\n",
    "    \"campaign launch\", \"policy announcement\", \"debate\", \"press conference\", \"town hall\",\n",
    "    \"doorstop\", \"scandal\", \"gaffe\", \"marginal seat\", \"safe seat\",\n",
    "    \n",
    "    # Media and social media terms\n",
    "    \"newspoll\", \"polling\", \"opinion poll\", \"media coverage\", \"social media\", \"hashtag\",\n",
    "    \"viral\", \"fact check\", \"misinformation\", \"political advertising\",\n",
    "    \n",
    "    # Election result terms\n",
    "    \"counting\", \"vote count\", \"scrutineer\", \"results\", \"win\", \"lose\", \"victory\", \"defeat\",\n",
    "    \"landslide\", \"tight race\", \"swing\", \"mandate\", \"primary vote\", \"two-party preferred\",\n",
    "    \"2pp\", \"preferences\", \"minority government\", \"majority government\",\n",
    "    \n",
    "    # Election time and place\n",
    "    \"election day\", \"pre-poll\", \"early voting\", \"postal vote\", \"voting booth\", \"polling place\",\n",
    "    \"ballot box\", \"electoral commission\",\n",
    "    \n",
    "    # Voter behavior and sentiment\n",
    "    \"voter\", \"turnout\", \"apathy\", \"engagement\", \"frustration\", \"hope\", \"change\", \"status quo\",\n",
    "    \"protest vote\", \"tactical voting\", \"donkey vote\", \"informal vote\"\n",
    "]\n",
    "\n",
    "# SA3 region names in Australia\n",
    "sa3_names = [\n",
    "    \"Adelaide City\", \"Adelaide Hills\", \"Albany\", \"Albury\", \"Alice Springs\", \"Armadale\", \n",
    "    \"Armidale\", \"Auburn\", \"Augusta - Margaret River - Busselton\", \"Bald Hills - Everton Park\", \n",
    "    \"Ballarat\", \"Bankstown\", \"Banyule\", \"Barkly\", \"Barossa\", \"Barwon - West\", \"Bathurst\", \n",
    "    \"Baulkham Hills\", \"Baw Baw\", \"Bayside\", \"Bayswater - Bassendean\", \"Beaudesert\", \"Beenleigh\", \n",
    "    \"Belconnen\", \"Belmont - Victoria Park\", \"Bendigo\", \"Biloela\", \"Blacktown\", \"Blacktown - North\", \n",
    "    \"Blue Mountains\", \"Blue Mountains - South\", \"Boroondara\", \"Botany\", \"Bourke - Cobar - Coonamble\", \n",
    "    \"Bowen Basin - North\", \"Bribie - Beachmere\", \"Brighton\", \"Brimbank\", \"Bringelly - Green Valley\", \n",
    "    \"Brisbane Inner\", \"Brisbane Inner - East\", \"Brisbane Inner - North\", \"Brisbane Inner - West\", \n",
    "    \"Broadbeach - Burleigh\", \"Broken Hill and Far West\", \"Browns Plains\", \"Brunswick - Coburg\", \n",
    "    \"Buderim\", \"Bunbury\", \"Bundaberg\", \"Burnett\", \"Burnie - Ulverstone\", \"Burnside\", \"Caboolture\", \n",
    "    \"Caboolture Hinterland\", \"Cairns - North\", \"Cairns - South\", \"Caloundra\", \"Camden\", \"Campaspe\", \n",
    "    \"Campbelltown (NSW)\", \"Campbelltown (SA)\", \"Canada Bay\", \"Canberra East\", \"Canning\", \"Canterbury\", \n",
    "    \"Capalaba\", \"Cardinia\", \"Carindale\", \"Carlingford\", \"Casey - North\", \"Casey - South\", \"Centenary\", \n",
    "    \"Central Highlands (Qld)\", \"Central Highlands (Tas.)\", \"Charles Sturt\", \"Charters Towers - Ayr - Ingham\", \n",
    "    \"Chatswood - Lane Cove\", \"Chermside\", \"Christmas Island\", \"Clarence Valley\", \"Cleveland - Stradbroke\", \n",
    "    \"Cockburn\", \"Cocos (Keeling) Islands\", \"Coffs Harbour\", \"Colac - Corangamite\", \"Coolangatta\", \n",
    "    \"Cottesloe - Claremont\", \"Creswick - Daylesford - Ballan\", \"Cronulla - Miranda - Caringbah\", \n",
    "    \"Daly - Tiwi - West Arnhem\", \"Dandenong\", \"Dapto - Port Kembla\", \"Darebin - North\", \"Darebin - South\", \n",
    "    \"Darling Downs (West) - Maranoa\", \"Darling Downs - East\", \"Darwin City\", \"Darwin Suburbs\", \"Devonport\", \n",
    "    \"Dubbo\", \"Dural - Wisemans Ferry\", \"East Arnhem\", \"East Pilbara\", \"Eastern Suburbs - North\", \n",
    "    \"Eastern Suburbs - South\", \"Esperance\", \"Essendon\", \"Eyre Peninsula and South West\", \"Fairfield\", \n",
    "    \"Far North\", \"Fleurieu - Kangaroo Island\", \"Forest Lake - Oxley\", \"Frankston\", \"Fremantle\", \"Gascoyne\", \n",
    "    \"Gawler - Two Wells\", \"Geelong\", \"Gippsland - East\", \"Gippsland - South West\", \"Gladstone\", \"Glen Eira\", \n",
    "    \"Glenelg - Southern Grampians\", \"Gold Coast - North\", \"Gold Coast Hinterland\", \"Goldfields\", \"Gosford\", \n",
    "    \"Gosnells\", \"Goulburn - Mulwaree\", \"Grampians\", \"Granite Belt\", \"Great Lakes\", \"Griffith - Murrumbidgee (West)\", \n",
    "    \"Gungahlin\", \"Gympie - Cooloola\", \"Hawkesbury\", \"Heathcote - Castlemaine - Kyneton\", \"Hervey Bay\", \n",
    "    \"Hobart - North East\", \"Hobart - North West\", \"Hobart - South and West\", \"Hobart Inner\", \"Hobsons Bay\", \n",
    "    \"Holdfast Bay\", \"Holland Park - Yeronga\", \"Hornsby\", \"Huon - Bruny Island\", \"Hurstville\", \n",
    "    \"Illawarra Catchment Reserve\", \"Innisfail - Cassowary Coast\", \"Inverell - Tenterfield\", \"Ipswich Hinterland\", \n",
    "    \"Ipswich Inner\", \"Jervis Bay\", \"Jimboomba\", \"Joondalup\", \"Kalamunda\", \"Katherine\", \"Keilor\", \n",
    "    \"Kempsey - Nambucca\", \"Kenmore - Brookfield - Moggill\", \"Kiama - Shellharbour\", \"Kimberley\", \"Kingston\", \n",
    "    \"Knox\", \"Kogarah - Rockdale\", \"Ku-ring-gai\", \"Kwinana\", \"Lachlan Valley\", \"Lake Macquarie - East\", \n",
    "    \"Lake Macquarie - West\", \"Latrobe Valley\", \"Launceston\", \"Leichhardt\", \"Limestone Coast\", \"Litchfield\", \n",
    "    \"Lithgow - Mudgee\", \"Liverpool\", \"Loddon - Elmore\", \"Loganlea - Carbrook\", \"Lord Howe Island\", \n",
    "    \"Lower Hunter\", \"Lower Murray\", \"Lower North\", \"Macedon Ranges\", \"Mackay\", \"Maitland\", \"Mandurah\", \n",
    "    \"Manjimup\", \"Manly\", \"Manningham - East\", \"Manningham - West\", \"Maribyrnong\", \"Marion\", \"Maroochy\", \n",
    "    \"Maroondah\", \"Marrickville - Sydenham - Petersham\", \"Maryborough\", \"Maryborough - Pyrenees\", \n",
    "    \"Meander Valley - West Tamar\", \"Melbourne City\", \"Melton - Bacchus Marsh\", \"Melville\", \n",
    "    \"Merrylands - Guildford\", \"Mid North\", \"Mid West\", \"Mildura\", \"Mitcham\", \"Moira\", \"Molonglo\", \n",
    "    \"Monash\", \"Moree - Narrabri\", \"Moreland - North\", \"Mornington Peninsula\", \"Mount Druitt\", \"Mt Gravatt\", \n",
    "    \"Mudgeeraba - Tallebudgera\", \"Mundaring\", \"Murray River - Swan Hill\", \"Murray and Mallee\", \"Nambour\", \n",
    "    \"Narangba - Burpengary\", \"Nathan\", \"Nerang\", \"Newcastle\", \"Nillumbik - Kinglake\", \"Noosa\", \n",
    "    \"Noosa Hinterland\", \"Norfolk Island\", \"North Canberra\", \"North East\", \"North Lakes\", \n",
    "    \"North Sydney - Mosman\", \"Norwood - Payneham - St Peters\", \"Nundah\", \"Onkaparinga\", \"Orange\", \n",
    "    \"Ormeau - Oxenford\", \"Outback - North\", \"Outback - North and East\", \"Outback - South\", \"Palmerston\", \n",
    "    \"Parramatta\", \"Pennant Hills - Epping\", \"Penrith\", \"Perth City\", \"Pittwater\", \"Playford\", \n",
    "    \"Port Adelaide - East\", \"Port Adelaide - West\", \"Port Douglas - Daintree\", \"Port Macquarie\", \n",
    "    \"Port Phillip\", \"Port Stephens\", \"Prospect - Walkerville\", \"Queanbeyan\", \"Redcliffe\", \n",
    "    \"Richmond - Windsor\", \"Richmond Valley - Coastal\", \"Richmond Valley - Hinterland\", \"Robina\", \n",
    "    \"Rockhampton\", \"Rockingham\", \"Rocklea - Acacia Ridge\", \"Rouse Hill - McGraths Hill\", \n",
    "    \"Ryde - Hunters Hill\", \"Salisbury\", \"Sandgate\", \"Serpentine - Jarrahdale\", \"Shepparton\", \n",
    "    \"Sherwood - Indooroopilly\", \"Shoalhaven\", \"Snowy Mountains\", \"Sorell - Dodges Ferry\", \n",
    "    \"South Canberra\", \"South Coast\", \"South East Coast\", \"South Perth\", \"Southern Highlands\", \n",
    "    \"Southport\", \"Springfield - Redbank\", \"Springwood - Kingston\", \"St Marys\", \"Stirling\", \n",
    "    \"Stonnington - East\", \"Stonnington - West\", \"Strathfield - Burwood - Ashfield\", \"Strathpine\", \n",
    "    \"Sunbury\", \"Sunnybank\", \"Sunshine Coast Hinterland\", \"Surf Coast - Bellarine Peninsula\", \n",
    "    \"Surfers Paradise\", \"Sutherland - Menai - Heathcote\", \"Swan\", \"Sydney Inner City\", \n",
    "    \"Tablelands (East) - Kuranda\", \"Tamworth - Gunnedah\", \"Taree - Gloucester\", \"Tea Tree Gully\", \n",
    "    \"The Gap - Enoggera\", \"The Hills District\", \"Toowoomba\", \"Townsville\", \"Tuggeranong\", \n",
    "    \"Tullamarine - Broadmeadows\", \"Tumut - Tumbarumba\", \"Tweed Valley\", \"Unley\", \"Upper Goulburn Valley\", \n",
    "    \"Upper Hunter\", \"Upper Murray exc. Albury\", \"Uriarra - Namadgi\", \"Wagga Wagga\", \"Wangaratta - Benalla\", \n",
    "    \"Wanneroo\", \"Warringah\", \"Warrnambool\", \"Wellington\", \"West Coast\", \"West Pilbara\", \"West Torrens\", \n",
    "    \"Weston Creek\", \"Wheat Belt - North\", \"Wheat Belt - South\", \"Whitehorse - East\", \"Whitehorse - West\", \n",
    "    \"Whitsunday\", \"Whittlesea - Wallan\", \"Woden Valley\", \"Wodonga - Alpine\", \"Wollondilly\", \"Wollongong\", \n",
    "    \"Wyndham\", \"Wynnum - Manly\", \"Wyong\", \"Yarra\", \"Yarra Ranges\", \"Yorke Peninsula\", \"Young - Yass\"\n",
    "]\n",
    "\n",
    "# Add major cities and states/territories to improve location matching\n",
    "major_locations = [\n",
    "    \"Sydney\", \"Melbourne\", \"Brisbane\", \"Perth\", \"Adelaide\", \"Canberra\", \"Hobart\", \"Darwin\",\n",
    "    \"Gold Coast\", \"Newcastle\", \"Wollongong\", \"Geelong\", \"Cairns\", \"Townsville\",\n",
    "    \"New South Wales\", \"Victoria\", \"Queensland\", \"Western Australia\", \"South Australia\", \n",
    "    \"Tasmania\", \"Northern Territory\", \"Australian Capital Territory\",\n",
    "    \"NSW\", \"VIC\", \"QLD\", \"WA\", \"SA\", \"TAS\", \"NT\", \"ACT\"\n",
    "]\n",
    "\n",
    "# Combine all locations\n",
    "all_locations = sa3_names + major_locations\n",
    "\n",
    "# Common Australian election-related tags\n",
    "election_tags = [\n",
    "    \"auspol\", \"ausvotes\", \"australiavotes\", \"fedpol\", \"democracy\", \"auspol2025\",\n",
    "    \"auselection\", \"auselection2025\", \"election\", \"elections\", \"electionday\",\n",
    "    \"alp\", \"greens\", \"liberals\", \"nswpol\", \"vicpol\", \"qldpol\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45ec58d",
   "metadata": {},
   "source": [
    "### Draw figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d7354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute query\n",
    "try:\n",
    "    # First validate connection\n",
    "    if not es.ping():\n",
    "        print(\"Warning: Unable to connect to Elasticsearch. Please check connection settings.\")\n",
    "    else:\n",
    "        print(\"Elasticsearch connection successful!\")\n",
    "    \n",
    "    # Check if index exists\n",
    "    if not es.indices.exists(index=\"socialplatform\"):\n",
    "        print(\"Error: Index 'socialplatform' does not exist. Please check index name.\")\n",
    "    else:\n",
    "        print(\"Index 'socialplatform' found\")\n",
    "        \n",
    "        # Execute query\n",
    "        all_resp = es.search(\n",
    "            index=\"socialplatform\",\n",
    "            body=query_body\n",
    "        )\n",
    "        \n",
    "        total_hits = all_resp[\"hits\"][\"total\"][\"value\"]\n",
    "        print(f\"Total hits: {total_hits}\")\n",
    "        \n",
    "        if total_hits == 0:\n",
    "            print(\"No matching records found. Please try the following:\")\n",
    "            print(\"1. Reduce the number of SA3 regions used\")\n",
    "            print(\"2. Use more general search terms\")\n",
    "            print(\"3. Verify if relevant data exists in the index\")\n",
    "            \n",
    "            # Create empty DataFrame to avoid subsequent processing errors\n",
    "            df = pd.DataFrame(columns=[\"location\", \"sentiment\", \"date\", \"tags\", \"election_terms\", \"content_preview\"])\n",
    "        else:\n",
    "            # Extract results\n",
    "            hits = all_resp[\"hits\"][\"hits\"]\n",
    "            print(f\"Actual number of records retrieved: {len(hits)}\")\n",
    "            \n",
    "            # Data processing\n",
    "            records = []\n",
    "            for hit in hits:\n",
    "                source = hit[\"_source\"]\n",
    "                \n",
    "                # Get key fields, using get method to safely handle potentially missing fields\n",
    "                sentiment = source.get(\"sentiment\", 0)\n",
    "                sentiment_label = source.get(\"sentimentLabel\", \"\")\n",
    "                keywords_list = source.get(\"keywords\", [])\n",
    "                \n",
    "                # Extract content from data object\n",
    "                data_obj = source.get(\"data\", {})\n",
    "                content = data_obj.get(\"content\", \"\")\n",
    "                created_at = data_obj.get(\"createdAt\", source.get(\"fetchedAt\", \"\"))\n",
    "                tags = data_obj.get(\"tags\", [])\n",
    "                \n",
    "                # Process location information\n",
    "                matched_locations = []\n",
    "                \n",
    "                # 1. First look for matching SA3 regions in keywords\n",
    "                for loc in all_locations:\n",
    "                    if loc in keywords_list:\n",
    "                        matched_locations.append(loc)\n",
    "                \n",
    "                # 2. If no locations found in keywords, try finding them in the content\n",
    "                if not matched_locations:\n",
    "                    content_lower = content.lower()\n",
    "                    for loc in all_locations:\n",
    "                        if loc.lower() in content_lower:\n",
    "                            matched_locations.append(loc)\n",
    "                \n",
    "                # 3. If still no location, use default value\n",
    "                if not matched_locations:\n",
    "                    matched_locations = [\"unknown_location\"]\n",
    "                \n",
    "                # Extract matching election keywords\n",
    "                matched_election_terms = []\n",
    "                for term in election_keywords:\n",
    "                    # Check keywords array\n",
    "                    if term in keywords_list:\n",
    "                        matched_election_terms.append(term)\n",
    "                    # Check content (for cases where keywords weren't extracted)\n",
    "                    elif term.lower() in content.lower():\n",
    "                        matched_election_terms.append(term)\n",
    "                \n",
    "                # Add matching tags\n",
    "                matched_election_tags = [tag for tag in tags if tag in election_tags]\n",
    "                \n",
    "                # Get source platform information\n",
    "                source_platform = source.get(\"platform\", \"unknown\")\n",
    "                \n",
    "                # Process date\n",
    "                try:\n",
    "                    date = datetime.fromisoformat(created_at.replace('Z', '+00:00'))\n",
    "                    date_str = date.strftime('%Y-%m-%d')\n",
    "                except Exception as e:\n",
    "                    date_str = \"unknown\"\n",
    "                \n",
    "                # Add matching records\n",
    "                for location in matched_locations:\n",
    "                    records.append({\n",
    "                        \"location\": location,\n",
    "                        \"sentiment\": sentiment,\n",
    "                        \"sentiment_label\": sentiment_label,\n",
    "                        \"date\": date_str,\n",
    "                        \"source\": source_platform,\n",
    "                        \"tags\": matched_election_tags,\n",
    "                        \"election_terms\": matched_election_terms,\n",
    "                        \"content_preview\": content[:150] + \"...\" if len(content) > 150 else content,\n",
    "                        \"score\": hit.get(\"_score\", 0)  # Add relevance score\n",
    "                    })\n",
    "            \n",
    "            # Create DataFrame\n",
    "            df = pd.DataFrame(records)\n",
    "        \n",
    "        # Basic data exploration\n",
    "        print(f\"\\nNumber of processed records: {len(df)}\")\n",
    "        \n",
    "        if len(df) > 0:\n",
    "            # Get most common locations\n",
    "            print(\"\\nMost common locations (Top 10):\")\n",
    "            location_counts = df['location'].value_counts().head(10)\n",
    "            for loc, count in location_counts.items():\n",
    "                print(f\"  {loc}: {count}\")\n",
    "            \n",
    "            print(\"\\nSentiment analysis overview:\")\n",
    "            print(df['sentiment'].describe())\n",
    "            \n",
    "            if 'sentiment_label' in df.columns and not df['sentiment_label'].isna().all():\n",
    "                print(\"\\nSentiment label distribution:\")\n",
    "                print(df['sentiment_label'].value_counts())\n",
    "            \n",
    "            if 'tags' in df.columns:\n",
    "                # Flatten tag lists\n",
    "                all_tags = []\n",
    "                for tag_list in df['tags']:\n",
    "                    if isinstance(tag_list, list) and tag_list:\n",
    "                        all_tags.extend(tag_list)\n",
    "                \n",
    "                if all_tags:\n",
    "                    tag_counts = pd.Series(all_tags).value_counts()\n",
    "                    print(\"\\nMost common election tags:\")\n",
    "                    print(tag_counts.head(10))\n",
    "            \n",
    "            if 'election_terms' in df.columns:\n",
    "                # Flatten election keyword lists\n",
    "                all_terms = []\n",
    "                for term_list in df['election_terms']:\n",
    "                    if isinstance(term_list, list) and term_list:\n",
    "                        all_terms.extend(term_list)\n",
    "                \n",
    "                if all_terms:\n",
    "                    term_counts = pd.Series(all_terms).value_counts()\n",
    "                    print(\"\\nMost common election keywords:\")\n",
    "                    print(term_counts.head(10))\n",
    "            \n",
    "            print(\"\\nRecord date range:\")\n",
    "            if 'date' in df.columns and df['date'].nunique() > 1:\n",
    "                df_with_dates = df[df['date'] != 'unknown']\n",
    "                if len(df_with_dates) > 0:\n",
    "                    print(f\"Earliest: {df_with_dates['date'].min()}\")\n",
    "                    print(f\"Latest: {df_with_dates['date'].max()}\")\n",
    "                else:\n",
    "                    print(\"No valid date records\")\n",
    "            \n",
    "            print(\"\\nContent preview examples:\")\n",
    "            if len(df) > 0 and 'content_preview' in df.columns:\n",
    "                for i, preview in enumerate(df['content_preview'].head(3)):\n",
    "                    print(f\"\\nRecord {i+1}:\")\n",
    "                    print(preview)\n",
    "            \n",
    "            # Visualization section\n",
    "            try:\n",
    "                if len(df) >= 10:\n",
    "                    # 1. Comparison of record counts by region\n",
    "                    plt.figure(figsize=(12, 8))\n",
    "                    location_counts = df['location'].value_counts().head(15)\n",
    "                    location_counts.plot(kind='barh', color='steelblue')\n",
    "                    plt.title('Election-Related Record Counts by Region', fontsize=14)\n",
    "                    plt.xlabel('Record Count', fontsize=12)\n",
    "                    plt.ylabel('Region', fontsize=12)\n",
    "                    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "                    plt.tight_layout()\n",
    "                    plt.savefig('election_location_counts.png')\n",
    "                    print(\"\\nCreated region distribution chart and saved as 'election_location_counts.png'\")\n",
    "                    \n",
    "                    # 2. Sentiment analysis grouped by state/territory\n",
    "                    # Create state/territory mapping\n",
    "                    state_mapping = {\n",
    "                        'NSW': ['Sydney', 'Newcastle', 'Wollongong', 'New South Wales', 'NSW'],\n",
    "                        'VIC': ['Melbourne', 'Geelong', 'Victoria', 'VIC'],\n",
    "                        'QLD': ['Brisbane', 'Gold Coast', 'Cairns', 'Townsville', 'Queensland', 'QLD'],\n",
    "                        'WA': ['Perth', 'Western Australia', 'WA'],\n",
    "                        'SA': ['Adelaide', 'South Australia', 'SA'],\n",
    "                        'TAS': ['Hobart', 'Tasmania', 'TAS'],\n",
    "                        'NT': ['Darwin', 'Northern Territory', 'NT'],\n",
    "                        'ACT': ['Canberra', 'Australian Capital Territory', 'ACT']\n",
    "                    }\n",
    "                    \n",
    "                    # Add state/territory column\n",
    "                    df['state'] = 'Other'\n",
    "                    for state, locations in state_mapping.items():\n",
    "                        df.loc[df['location'].isin(locations), 'state'] = state\n",
    "                    \n",
    "                    # Assign states/territories to SA3 regions\n",
    "                    # This needs more detailed mapping, this is a simple example\n",
    "                    sa3_state_prefixes = {\n",
    "                        'NSW': ['Sydney', 'Newcastle', 'Wollongong', 'Blue Mountains', 'Central Coast', 'Illawarra', \n",
    "                                'Hunter', 'New England', 'North Coast', 'South Coast', 'Albury', 'Wagga Wagga'],\n",
    "                        'VIC': ['Melbourne', 'Geelong', 'Bendigo', 'Ballarat', 'Gippsland', 'Mornington'],\n",
    "                        'QLD': ['Brisbane', 'Gold Coast', 'Sunshine Coast', 'Cairns', 'Townsville', 'Mackay', \n",
    "                                'Rockhampton', 'Toowoomba', 'Bundaberg', 'Hervey Bay', 'Darling Downs'],\n",
    "                        'WA': ['Perth', 'Bunbury', 'Mandurah', 'Pilbara', 'Kimberley', 'Goldfields', 'Wheatbelt'],\n",
    "                        'SA': ['Adelaide', 'Barossa', 'Yorke', 'Eyre', 'Murray'],\n",
    "                        'TAS': ['Hobart', 'Launceston', 'Burnie', 'Devonport', 'East Coast'],\n",
    "                        'NT': ['Darwin', 'Alice Springs', 'Katherine', 'Arnhem', 'Barkly'],\n",
    "                        'ACT': ['Canberra', 'Belconnen', 'Gungahlin', 'Tuggeranong', 'Woden']\n",
    "                    }\n",
    "                    \n",
    "                    for state, prefixes in sa3_state_prefixes.items():\n",
    "                        for location in df['location'].unique():\n",
    "                            if df.loc[df['location'] == location, 'state'].iloc[0] == 'Other':\n",
    "                                for prefix in prefixes:\n",
    "                                    if prefix in location:\n",
    "                                        df.loc[df['location'] == location, 'state'] = state\n",
    "                                        break\n",
    "                    \n",
    "                    # Sentiment analysis by state/territory\n",
    "                    if len(df['state'].unique()) > 1:\n",
    "                        plt.figure(figsize=(10, 6))\n",
    "                        sns.boxplot(x='state', y='sentiment', data=df)\n",
    "                        plt.title('Sentiment Distribution for Election Topics by State/Territory', fontsize=14)\n",
    "                        plt.xlabel('State/Territory', fontsize=12)\n",
    "                        plt.ylabel('Sentiment Score', fontsize=12)\n",
    "                        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "                        plt.tight_layout()\n",
    "                        plt.savefig('election_sentiment_by_state.png')\n",
    "                        print(\"Created state/territory sentiment analysis chart and saved as 'election_sentiment_by_state.png'\")\n",
    "                    \n",
    "                    # 3. Election keyword word cloud\n",
    "                    if 'election_terms' in df.columns and sum(df['election_terms'].apply(len)) > 0:\n",
    "                        try:\n",
    "                            from wordcloud import WordCloud\n",
    "                            all_terms = []\n",
    "                            for term_list in df['election_terms']:\n",
    "                                if isinstance(term_list, list) and term_list:\n",
    "                                    all_terms.extend(term_list)\n",
    "                            \n",
    "                            if all_terms:\n",
    "                                term_counts = pd.Series(all_terms).value_counts().to_dict()\n",
    "                                \n",
    "                                plt.figure(figsize=(12, 8))\n",
    "                                wordcloud = WordCloud(width=800, height=500, background_color='white', \n",
    "                                                      max_words=100, contour_width=3, contour_color='steelblue')\n",
    "                                wordcloud.generate_from_frequencies(term_counts)\n",
    "                                plt.imshow(wordcloud, interpolation='bilinear')\n",
    "                                plt.axis('off')\n",
    "                                plt.tight_layout()\n",
    "                                plt.savefig('election_terms_wordcloud.png')\n",
    "                                print(\"Created election keyword word cloud and saved as 'election_terms_wordcloud.png'\")\n",
    "                        except ImportError:\n",
    "                            print(\"Tip: Install wordcloud package to generate word clouds: pip install wordcloud\")\n",
    "                            \n",
    "                            # Fall back to bar chart\n",
    "                            term_counts = pd.Series(all_terms).value_counts().head(15)\n",
    "                            plt.figure(figsize=(12, 8))\n",
    "                            term_counts.plot(kind='barh', color='steelblue')\n",
    "                            plt.title('Election Keyword Distribution', fontsize=14)\n",
    "                            plt.xlabel('Frequency', fontsize=12)\n",
    "                            plt.ylabel('Keyword', fontsize=12)\n",
    "                            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "                            plt.tight_layout()\n",
    "                            plt.savefig('election_terms_counts.png')\n",
    "                            print(\"Created election keyword distribution chart and saved as 'election_terms_counts.png'\")\n",
    "                    \n",
    "                    # 4. Time trend analysis\n",
    "                    if 'date' in df.columns and df['date'].nunique() > 3:\n",
    "                        time_df = df[df['date'] != 'unknown'].copy()\n",
    "                        if len(time_df) > 10:\n",
    "                            time_df['date'] = pd.to_datetime(time_df['date'])\n",
    "                            daily_counts = time_df.groupby(time_df['date']).size().reset_index(name='count')\n",
    "                            daily_sentiment = time_df.groupby(time_df['date'])['sentiment'].mean().reset_index()\n",
    "                            \n",
    "                            # Post volume time trend\n",
    "                            plt.figure(figsize=(12, 6))\n",
    "                            plt.plot(daily_counts['date'], daily_counts['count'], \n",
    "                                    marker='o', linestyle='-', color='royalblue')\n",
    "                            plt.title('Election-Related Post Count Over Time', fontsize=14)\n",
    "                            plt.xlabel('Date', fontsize=12)\n",
    "                            plt.ylabel('Post Count', fontsize=12)\n",
    "                            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "                            plt.xticks(rotation=45)\n",
    "                            plt.tight_layout()\n",
    "                            plt.savefig('election_posts_trend.png')\n",
    "                            print(\"Created post count trend chart and saved as 'election_posts_trend.png'\")\n",
    "                            \n",
    "                            # Sentiment time trend\n",
    "                            plt.figure(figsize=(12, 6))\n",
    "                            plt.plot(daily_sentiment['date'], daily_sentiment['sentiment'], \n",
    "                                    marker='o', linestyle='-', color='teal')\n",
    "                            plt.axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "                            plt.title('Election Topic Sentiment Trend Over Time', fontsize=14)\n",
    "                            plt.xlabel('Date', fontsize=12)\n",
    "                            plt.ylabel('Average Sentiment Score', fontsize=12)\n",
    "                            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "                            plt.xticks(rotation=45)\n",
    "                            plt.tight_layout()\n",
    "                            plt.savefig('election_sentiment_trend.png')\n",
    "                            print(\"Created sentiment trend chart and saved as 'election_sentiment_trend.png'\")\n",
    "                    \n",
    "                    # 5. Popular regions sentiment heatmap\n",
    "                    if len(df) >= 20:\n",
    "                        top_locations = df['location'].value_counts().head(10).index.tolist()\n",
    "                        sentiment_pivot = pd.DataFrame()\n",
    "                        \n",
    "                        # Get sentiment distribution for these regions\n",
    "                        for loc in top_locations:\n",
    "                            loc_sentiments = df[df['location'] == loc]['sentiment']\n",
    "                            if len(loc_sentiments) >= 5:  # Ensure enough data\n",
    "                                sentiment_pivot[loc] = pd.cut(\n",
    "                                    loc_sentiments, \n",
    "                                    bins=[-1, -0.5, -0.25, 0, 0.25, 0.5, 1],\n",
    "                                    labels=['Very Negative', 'Negative', 'Slightly Negative', \n",
    "                                            'Neutral', 'Slightly Positive', 'Positive']\n",
    "                                ).value_counts(normalize=True)\n",
    "                        \n",
    "                        if not sentiment_pivot.empty and sentiment_pivot.shape[1] >= 3:\n",
    "                            plt.figure(figsize=(14, 8))\n",
    "                            sns.heatmap(sentiment_pivot.transpose(), annot=True, cmap='YlGnBu', fmt='.2f',\n",
    "                                      cbar_kws={'label': 'Proportion'})\n",
    "                            plt.title('Sentiment Distribution Heatmap for Popular Regions', fontsize=14)\n",
    "                            plt.ylabel('Region', fontsize=12)\n",
    "                            plt.xlabel('Sentiment Category', fontsize=12)\n",
    "                            plt.tight_layout()\n",
    "                            plt.savefig('election_sentiment_heatmap.png')\n",
    "                            print(\"Created sentiment distribution heatmap and saved as 'election_sentiment_heatmap.png'\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating visualizations: {e}\")\n",
    "        else:\n",
    "            print(\"No records found, cannot perform data exploration.\")\n",
    "            \n",
    "        # Save processed data\n",
    "        if len(df) > 0:\n",
    "            try:\n",
    "                export_filename = 'australian_election_data.csv'\n",
    "                df.to_csv(export_filename, index=False)\n",
    "                print(f\"\\nData exported to {export_filename}\")\n",
    "                \n",
    "                # Export results summary\n",
    "                summary = {\n",
    "                    \"Query Time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                    \"Total Hits\": total_hits,\n",
    "                    \"Processed Records\": len(df),\n",
    "                    \"Location Distribution\": df['location'].value_counts().to_dict(),\n",
    "                    \"Sentiment Statistics\": {\n",
    "                        \"Mean\": float(df['sentiment'].mean()),\n",
    "                        \"Median\": float(df['sentiment'].median()),\n",
    "                        \"Standard Deviation\": float(df['sentiment'].std()),\n",
    "                        \"Minimum\": float(df['sentiment'].min()),\n",
    "                        \"Maximum\": float(df['sentiment'].max())\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                if 'election_terms' in df.columns:\n",
    "                    all_terms = []\n",
    "                    for term_list in df['election_terms']:\n",
    "                        if isinstance(term_list, list) and term_list:\n",
    "                            all_terms.extend(term_list)\n",
    "                    \n",
    "                    if all_terms:\n",
    "                        summary[\"Popular Election Keywords\"] = pd.Series(all_terms).value_counts().head(20).to_dict()\n",
    "                \n",
    "                with open('election_analysis_summary.json', 'w') as f:\n",
    "                    json.dump(summary, f, indent=2)\n",
    "                print(\"Analysis summary exported to 'election_analysis_summary.json'\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error exporting data: {e}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Query execution error: {str(e)}\")\n",
    "    \n",
    "    # Diagnostic information\n",
    "    if \"ConnectionError\" in str(e):\n",
    "        print(\"Connection error: Cannot connect to Elasticsearch. Please check if the service is running and the network connection.\")\n",
    "    elif \"AuthenticationException\" in str(e):\n",
    "        print(\"Authentication error: Incorrect username or password.\")\n",
    "    elif \"index_not_found_exception\" in str(e):\n",
    "        print(\"Index error: Index 'socialplatform' does not exist.\")\n",
    "    elif \"SearchPhaseExecutionException\" in str(e):\n",
    "        print(\"Query error: Query syntax or parameters may be incorrect.\")\n",
    "    else:\n",
    "        print(\"Other error. Please check Elasticsearch logs for more information.\")\n",
    "\n",
    "print(\"\\nScript execution completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0690ebcc",
   "metadata": {},
   "source": [
    "## draw maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7707b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data():\n",
    "    \"\"\"Load data and perform preprocessing\"\"\"\n",
    "    \n",
    "    print(\"Starting data loading...\")  # 开始加载数据\n",
    "    \n",
    "    # Load CSV data\n",
    "    csv_path = 'australian_election_data.csv'\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"Error: {csv_path} not found\")  # 错误: 未找到文件\n",
    "        print(\"Please run the Elasticsearch query code first to ensure the data file is generated.\")  # 请先运行查询代码确保数据文件已生成\n",
    "        return None, None\n",
    "    \n",
    "    # Load election data\n",
    "    election_df = pd.read_csv(csv_path)\n",
    "    print(f\"Election data loaded with {len(election_df)} records\")  # 已加载选举数据，记录数\n",
    "    \n",
    "    # Count posts for each SA3 region\n",
    "    location_counts = election_df['location'].value_counts().reset_index()\n",
    "    location_counts.columns = ['SA3_NAME', 'post_count']\n",
    "    print(f\"Election data contains {len(location_counts)} different locations\")  # 选举数据中包含的不同地点数\n",
    "    \n",
    "    # Use the user-provided 2021 SA3 boundary data\n",
    "    shapefile_path = 'SA3_2021_AUST_SHP_GDA2020/SA3_2021_AUST_GDA2020.shp'\n",
    "    \n",
    "    if not os.path.exists(shapefile_path):\n",
    "        print(f\"Error: Specified shapefile not found: {shapefile_path}\")  # 错误: 未找到指定的shapefile\n",
    "        # Try to find in different subdirectories\n",
    "        alternative_paths = [\n",
    "            'SA3_2021_AUST_SHP_GDA2020/SA3_2021_AUST_GDA2020.shp',\n",
    "            'SA3_2021_AUST_GDA2020.shp',\n",
    "            'SA3_2021_AUST_SHP_GDA2020/SA3_2021_AUST.shp'\n",
    "        ]\n",
    "        \n",
    "        for path in alternative_paths:\n",
    "            if os.path.exists(path):\n",
    "                shapefile_path = path\n",
    "                print(f\"Found alternative file path: {path}\")  # 找到替代文件路径\n",
    "                break\n",
    "        else:\n",
    "            print(\"Please confirm the exact filename in the SA3_2021_AUST_SHP_GDA2020 folder\")  # 请确认文件夹中的具体文件名\n",
    "            print(\"Attempting to list files in the folder:\")  # 尝试列出该文件夹中的文件\n",
    "            try:\n",
    "                files = os.listdir('SA3_2021_AUST_SHP_GDA2020')\n",
    "                for file in files:\n",
    "                    if file.endswith('.shp'):\n",
    "                        print(f\" - {file}\")\n",
    "                        # If a .shp file is found, use it\n",
    "                        shapefile_path = os.path.join('SA3_2021_AUST_SHP_GDA2020', file)\n",
    "                        print(f\"Will use: {shapefile_path}\")  # 将使用该文件\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                print(f\"Error listing files: {e}\")  # 列出文件时出错\n",
    "                return None, location_counts\n",
    "    \n",
    "    try:\n",
    "        # Load map data\n",
    "        gdf = gpd.read_file(shapefile_path)\n",
    "        print(f\"SA3 boundary data loaded with {len(gdf)} regions\")  # 已加载SA3边界数据，区域数\n",
    "        \n",
    "        # Check coordinate system\n",
    "        if gdf.crs is None:\n",
    "            print(\"Warning: Map data has no coordinate reference system, setting to GDA2020...\")  # 警告: 地图数据没有坐标系统信息\n",
    "            gdf.crs = \"EPSG:7844\"  # GDA2020\n",
    "        else:\n",
    "            print(f\"Map data uses coordinate system: {gdf.crs}\")  # 地图数据使用的坐标系统\n",
    "        \n",
    "        # Display map data columns\n",
    "        print(\"Map data columns:\")  # 地图数据的列\n",
    "        print(gdf.columns.tolist())\n",
    "        \n",
    "        # Find the column containing SA3 names\n",
    "        sa3_name_col = None\n",
    "        for col in ['SA3_NAME_2021', 'SA3_NAME21', 'SA3_NAME', 'NAME']:\n",
    "            if col in gdf.columns:\n",
    "                sa3_name_col = col\n",
    "                print(f\"Using column '{col}' as SA3 name\")  # 使用该列作为SA3名称\n",
    "                break\n",
    "        \n",
    "        if sa3_name_col is None:\n",
    "            # Try to find any column that might contain names\n",
    "            for col in gdf.columns:\n",
    "                if 'name' in col.lower() or 'sa3' in col.lower():\n",
    "                    sa3_name_col = col\n",
    "                    print(f\"Using column '{col}' as SA3 name\")  # 使用该列作为SA3名称\n",
    "                    break\n",
    "        \n",
    "        if sa3_name_col is None:\n",
    "            print(\"Warning: Unable to determine SA3 name column. Here are all column values for the first few regions:\")  # 警告: 无法确定SA3名称列\n",
    "            print(gdf.head(1).to_dict('records'))\n",
    "            print(\"Please manually specify the SA3 name column\")  # 请手动指定SA3名称列\n",
    "            return None, location_counts\n",
    "        \n",
    "        # Normalize column names, using SA3_NAME as standard\n",
    "        gdf['SA3_NAME'] = gdf[sa3_name_col]\n",
    "        \n",
    "        # Find column containing state/territory names\n",
    "        state_col = None\n",
    "        for col in ['STATE_NAME_2021', 'STATE_NAME', 'STE_NAME21', 'STE_NAME']:\n",
    "            if col in gdf.columns:\n",
    "                state_col = col\n",
    "                print(f\"Using column '{col}' as state/territory name\")  # 使用该列作为州/领地名称\n",
    "                break\n",
    "        \n",
    "        if state_col:\n",
    "            gdf['STATE_NAME'] = gdf[state_col]\n",
    "        \n",
    "        return gdf, location_counts\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading SA3 boundary data: {e}\")  # 加载SA3边界数据时出错\n",
    "        return None, location_counts\n",
    "\n",
    "def merge_data(gdf, location_counts):\n",
    "    \"\"\"Merge map data and election post data\"\"\"\n",
    "    \n",
    "    if gdf is None:\n",
    "        print(\"Warning: No map data provided, cannot merge\")  # 警告: 未提供地图数据，无法合并\n",
    "        return None\n",
    "    \n",
    "    print(\"\\nStarting data merge...\")  # 开始合并数据\n",
    "    print(f\"Map data has {len(gdf)} regions\")  # 地图数据中的区域数\n",
    "    print(f\"Election data has {len(location_counts)} locations\")  # 选举数据中的地点数\n",
    "    \n",
    "    # Display some location names from each dataset as examples\n",
    "    print(\"\\nSome region names from map data:\")  # 地图数据中的一些区域名称\n",
    "    print(gdf['SA3_NAME'].head().tolist())\n",
    "    \n",
    "    print(\"\\nSome location names from election data:\")  # 选举数据中的一些地点名称\n",
    "    print(location_counts['SA3_NAME'].head().tolist())\n",
    "    \n",
    "    # Create normalized versions of location names for matching\n",
    "    gdf['name_lower'] = gdf['SA3_NAME'].str.strip().str.lower()\n",
    "    location_counts['name_lower'] = location_counts['SA3_NAME'].str.strip().str.lower()\n",
    "    \n",
    "    # Check direct match situation\n",
    "    map_names = set(gdf['name_lower'])\n",
    "    data_names = set(location_counts['name_lower'])\n",
    "    \n",
    "    # Calculate match rate\n",
    "    common_names = map_names.intersection(data_names)\n",
    "    match_percentage = len(common_names) / len(data_names) * 100 if data_names else 0\n",
    "    \n",
    "    print(f\"\\nDirect name matching: {len(common_names)} matches / {len(data_names)} total ({match_percentage:.1f}%)\")  # 名称直接匹配情况\n",
    "    \n",
    "    if match_percentage < 50:\n",
    "        print(\"Warning: Match rate below 50%, attempting name mapping\")  # 警告: 匹配率低于50%，尝试进行名称映射\n",
    "        \n",
    "        # Display some unmatched names\n",
    "        unmatched = data_names - common_names\n",
    "        print(\"\\nExamples of unmatched location names in election data:\")  # 选举数据中未匹配的地点名称示例\n",
    "        print(list(unmatched)[:10])\n",
    "        \n",
    "        # Create mapping dictionary\n",
    "        name_mapping = {}\n",
    "        \n",
    "        # First handle major cities and state/territory names\n",
    "        major_cities_states = {\n",
    "            'sydney': 'Sydney - City and Inner South',\n",
    "            'melbourne': 'Melbourne City',\n",
    "            'brisbane': 'Brisbane Inner',\n",
    "            'perth': 'Perth City',\n",
    "            'adelaide': 'Adelaide City',\n",
    "            'canberra': 'Canberra',\n",
    "            'hobart': 'Hobart',\n",
    "            'darwin': 'Darwin City',\n",
    "            'gold coast': 'Surfers Paradise',\n",
    "            'newcastle': 'Newcastle',\n",
    "            'wollongong': 'Wollongong',\n",
    "            'geelong': 'Geelong',\n",
    "            'cairns': 'Cairns - South',\n",
    "            'townsville': 'Townsville',\n",
    "            'nsw': 'Sydney - City and Inner South',  # Default to capital city\n",
    "            'vic': 'Melbourne City',\n",
    "            'qld': 'Brisbane Inner',\n",
    "            'wa': 'Perth City',\n",
    "            'sa': 'Adelaide City',\n",
    "            'tas': 'Hobart',\n",
    "            'nt': 'Darwin City',\n",
    "            'act': 'Canberra'\n",
    "        }\n",
    "        \n",
    "        # Apply major city and state mapping\n",
    "        for data_name_lower, map_name in major_cities_states.items():\n",
    "            # Find matching map name (normalized)\n",
    "            if data_name_lower in data_names:\n",
    "                matching_map_names = [name for name in gdf['SA3_NAME'] \n",
    "                                      if map_name.lower() in name.lower()]\n",
    "                \n",
    "                if matching_map_names:\n",
    "                    # Found match, use the first match\n",
    "                    original_data_names = [name for name in location_counts['SA3_NAME'] \n",
    "                                          if name.strip().lower() == data_name_lower]\n",
    "                    \n",
    "                    for original_name in original_data_names:\n",
    "                        name_mapping[original_name] = matching_map_names[0]\n",
    "        \n",
    "        # Then try partial matching\n",
    "        for data_name in location_counts['SA3_NAME']:\n",
    "            data_name_lower = data_name.strip().lower()\n",
    "            \n",
    "            # Skip if already matched or mapped\n",
    "            if data_name_lower in common_names or data_name in name_mapping:\n",
    "                continue\n",
    "            \n",
    "            # Try partial matching\n",
    "            best_match = None\n",
    "            best_score = 0\n",
    "            \n",
    "            # Try different matching strategies\n",
    "            for map_name in gdf['SA3_NAME']:\n",
    "                map_name_lower = map_name.strip().lower()\n",
    "                \n",
    "                # 1. Complete containment relationship\n",
    "                if data_name_lower in map_name_lower or map_name_lower in data_name_lower:\n",
    "                    # Calculate number of common words as match score\n",
    "                    score = len(set(data_name_lower.split()) & set(map_name_lower.split()))\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_match = map_name\n",
    "                \n",
    "                # 2. Word-level matching\n",
    "                data_words = set(data_name_lower.split())\n",
    "                map_words = set(map_name_lower.split())\n",
    "                \n",
    "                common_words = data_words & map_words\n",
    "                if len(common_words) >= 1 and len(common_words)/len(data_words) > 0.3:\n",
    "                    score = len(common_words)\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_match = map_name\n",
    "            \n",
    "            if best_match and best_score >= 1:\n",
    "                name_mapping[data_name] = best_match\n",
    "        \n",
    "        print(f\"Created {len(name_mapping)} name mappings\")  # 已创建的名称映射数\n",
    "        \n",
    "        # Apply mapping\n",
    "        location_counts['SA3_NAME_mapped'] = location_counts['SA3_NAME'].map(name_mapping)\n",
    "        \n",
    "        # For unmapped values, try direct matching again (case insensitive)\n",
    "        name_match_dict = {}\n",
    "        for data_name in location_counts[location_counts['SA3_NAME_mapped'].isna()]['SA3_NAME']:\n",
    "            data_name_lower = data_name.strip().lower()\n",
    "            for map_name in gdf['SA3_NAME']:\n",
    "                if map_name.strip().lower() == data_name_lower:\n",
    "                    name_match_dict[data_name] = map_name\n",
    "                    break\n",
    "        \n",
    "        # Update mapping\n",
    "        for data_name, map_name in name_match_dict.items():\n",
    "            mask = (location_counts['SA3_NAME'] == data_name) & (location_counts['SA3_NAME_mapped'].isna())\n",
    "            location_counts.loc[mask, 'SA3_NAME_mapped'] = map_name\n",
    "        \n",
    "        # For still unmapped values, try assigning to appropriate SA3 regions\n",
    "        # Here simply assign to capital city regions\n",
    "        state_capital_mapping = {\n",
    "            'nsw': 'Sydney - City and Inner South',\n",
    "            'vic': 'Melbourne City',\n",
    "            'qld': 'Brisbane Inner',\n",
    "            'wa': 'Perth City',\n",
    "            'sa': 'Adelaide City',\n",
    "            'tas': 'Hobart',\n",
    "            'nt': 'Darwin City',\n",
    "            'act': 'Canberra'\n",
    "        }\n",
    "        \n",
    "        # Find records containing these capital cities\n",
    "        capital_sa3s = {}\n",
    "        for state_code, capital_name in state_capital_mapping.items():\n",
    "            for sa3_name in gdf['SA3_NAME']:\n",
    "                if capital_name.lower() in sa3_name.lower():\n",
    "                    capital_sa3s[state_code] = sa3_name\n",
    "                    break\n",
    "        \n",
    "        # For unmapped, use \"unknown\"\n",
    "        mask = location_counts['SA3_NAME_mapped'].isna()\n",
    "        location_counts.loc[mask, 'SA3_NAME_mapped'] = \"Unknown Location\"\n",
    "        \n",
    "        # Display results after mapping\n",
    "        print(\"\\nSome location names after mapping:\")  # 映射后的部分地点名称\n",
    "        for i, (original, mapped) in enumerate(zip(location_counts['SA3_NAME'].head(10), \n",
    "                                                 location_counts['SA3_NAME_mapped'].head(10))):\n",
    "            print(f\"{i+1}. {original} -> {mapped}\")\n",
    "        \n",
    "        # Use mapped names\n",
    "        location_counts['SA3_NAME'] = location_counts['SA3_NAME_mapped']\n",
    "    \n",
    "    # Group by SA3_NAME and sum post_count\n",
    "    location_counts_agg = location_counts.groupby('SA3_NAME')['post_count'].sum().reset_index()\n",
    "    \n",
    "    # Merge data\n",
    "    merged_gdf = gdf.merge(location_counts_agg, on='SA3_NAME', how='left')\n",
    "    \n",
    "    # Check merged data\n",
    "    missing_count = merged_gdf['post_count'].isna().sum()\n",
    "    print(f\"\\nMerged data statistics:\")  # 合并后数据统计\n",
    "    print(f\"- Total regions: {len(merged_gdf)}\")  # 总区域数\n",
    "    print(f\"- Regions with post data: {len(merged_gdf) - missing_count}\")  # 有发帖数据的区域\n",
    "    print(f\"- Regions without post data: {missing_count}\")  # 缺少发帖数据的区域\n",
    "    \n",
    "    # Fill missing values\n",
    "    merged_gdf['post_count'].fillna(0, inplace=True)\n",
    "    \n",
    "    # Calculate basic statistics\n",
    "    if len(merged_gdf) > 0:\n",
    "        print(\"\\nPost count statistics:\")  # 发帖数量统计\n",
    "        print(merged_gdf['post_count'].describe())\n",
    "    \n",
    "    return merged_gdf\n",
    "\n",
    "def create_sa3_choropleth(merged_gdf, save_path='sa3_election_posts_map.png'):\n",
    "    \"\"\"Create election post heat map for SA3 regions\"\"\"\n",
    "    \n",
    "    if merged_gdf is None:\n",
    "        print(\"Cannot create map: Missing merged geographic data\")  # 无法创建地图：缺少合并的地理数据\n",
    "        \n",
    "        # Create a simple example figure for illustration\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.text(0.5, 0.5, \"SA3 map data missing\\nPlease confirm SA3 boundary data file\", \n",
    "                 ha='center', va='center', fontsize=16)\n",
    "        plt.axis('off')\n",
    "        plt.savefig('sa3_map_missing.png')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Saved error message figure to sa3_map_missing.png\")  # 已保存错误提示图\n",
    "        return\n",
    "    \n",
    "    print(\"\\nCreating SA3 region election post heat map...\")  # 开始创建SA3区域选举发帖热力地图\n",
    "    \n",
    "    # Check if data is empty\n",
    "    if merged_gdf.empty:\n",
    "        print(\"Error: Merged geographic data is empty\")  # 错误: 合并的地理数据为空\n",
    "        return\n",
    "    \n",
    "    # Prepare plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
    "    \n",
    "    # Calculate post count quantiles for color mapping\n",
    "    # Exclude zero values for better color distribution\n",
    "    nonzero_counts = merged_gdf['post_count'][merged_gdf['post_count'] > 0]\n",
    "    \n",
    "    if len(nonzero_counts) == 0:\n",
    "        print(\"Warning: No regions with non-zero post count\")  # 警告: 没有区域有非零发帖量\n",
    "        vmin = 0\n",
    "        vmax = 1\n",
    "    else:\n",
    "        vmin = nonzero_counts.min()\n",
    "        q95 = nonzero_counts.quantile(0.95)  # Use 95% quantile as max, avoid extreme values\n",
    "        vmax = max(q95, vmin + 1)  # Ensure vmax > vmin\n",
    "    \n",
    "    print(f\"Color mapping range: {vmin} to {vmax}\")  # 色彩映射范围\n",
    "    \n",
    "    # Create custom color map\n",
    "    cmap = LinearSegmentedColormap.from_list(\n",
    "        'election_cmap', ['#f7fbff', '#08519c'], N=256)\n",
    "    \n",
    "    # Use log scale for skewed distributions\n",
    "    norm = colors.LogNorm(vmin=max(0.1, vmin), vmax=max(vmax, 0.2))\n",
    "    \n",
    "    # Draw map\n",
    "    merged_gdf.plot(\n",
    "        column='post_count',\n",
    "        ax=ax,\n",
    "        cmap=cmap,\n",
    "        norm=norm,\n",
    "        edgecolor='#666666',\n",
    "        linewidth=0.2,\n",
    "        missing_kwds={'color': 'lightgrey'}\n",
    "    )\n",
    "    \n",
    "    # Add state boundaries (if available)\n",
    "    if 'STATE_NAME' in merged_gdf.columns:\n",
    "        # Dissolve to get state boundaries\n",
    "        state_gdf = merged_gdf.dissolve(by='STATE_NAME').reset_index()\n",
    "        # Draw state boundaries\n",
    "        state_gdf.boundary.plot(ax=ax, color='black', linewidth=1)\n",
    "    \n",
    "    # Add color bar\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, extend='max', shrink=0.7)\n",
    "    cbar.set_label('Election-related post count', fontsize=12)  # 选举相关发帖数量\n",
    "    \n",
    "    # Add title and annotations\n",
    "    plt.title('Australian SA3 Region Election-related Post Heat Map', fontsize=16, pad=20)  # 澳大利亚SA3区域选举相关发帖热力图\n",
    "    plt.figtext(0.5, 0.01, 'Data source: Social media election analysis', ha='center', fontsize=10)  # 数据来源: 社交媒体选举分析\n",
    "    \n",
    "    # Remove axes\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    # Save image\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Saved map to {save_path}\")  # 已保存地图\n",
    "    \n",
    "    # Additionally create a high contrast version, highlighting regions with posts\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
    "    \n",
    "    # Use categorical color scheme\n",
    "    merged_gdf['post_category'] = pd.cut(\n",
    "        merged_gdf['post_count'], \n",
    "        bins=[0, 1, 5, 10, 20, 50, 100, float('inf')],\n",
    "        labels=['0', '1-4', '5-9', '10-19', '20-49', '50-99', '100+']\n",
    "    )\n",
    "    \n",
    "    # Create color map for categories\n",
    "    category_cmap = {\n",
    "        '0': '#f7f7f7',\n",
    "        '1-4': '#d1e5f0',\n",
    "        '5-9': '#92c5de',\n",
    "        '10-19': '#4393c3',\n",
    "        '20-49': '#2166ac',\n",
    "        '50-99': '#053061',\n",
    "        '100+': '#01142b'\n",
    "    }\n",
    "    \n",
    "    merged_gdf['color'] = merged_gdf['post_category'].map(category_cmap)\n",
    "    \n",
    "    # Draw categorical map\n",
    "    merged_gdf.plot(\n",
    "        column='post_category',\n",
    "        ax=ax,\n",
    "        categorical=True,\n",
    "        cmap=plt.cm.get_cmap('Blues', 7),\n",
    "        edgecolor='#666666',\n",
    "        linewidth=0.2,\n",
    "        legend=True,\n",
    "        legend_kwds={'title': 'Post count', 'loc': 'lower right'}  # 发帖数量\n",
    "    )\n",
    "    \n",
    "    # Add state boundaries (if available)\n",
    "    if 'STATE_NAME' in merged_gdf.columns:\n",
    "        # Dissolve to get state boundaries\n",
    "        state_gdf = merged_gdf.dissolve(by='STATE_NAME').reset_index()\n",
    "        # Draw state boundaries\n",
    "        state_gdf.boundary.plot(ax=ax, color='black', linewidth=1)\n",
    "    \n",
    "    # Add title and annotations\n",
    "    plt.title('Australian SA3 Region Election-related Post Distribution Map', fontsize=16, pad=20)  # 澳大利亚SA3区域选举相关发帖分布图\n",
    "    plt.figtext(0.5, 0.01, 'Data source: Social media election analysis', ha='center', fontsize=10)  # 数据来源: 社交媒体选举分析\n",
    "    \n",
    "    # Remove axes\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    # Save image\n",
    "    category_map_path = 'sa3_election_posts_category_map.png'\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(category_map_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Saved category map to {category_map_path}\")  # 已保存分类地图\n",
    "    \n",
    "def create_state_level_map(merged_gdf, save_path='state_election_posts_map.png'):\n",
    "    \"\"\"Create state/territory level election post heat map, handling empty geometries\"\"\"\n",
    "    \n",
    "    if merged_gdf is None or 'STATE_NAME' not in merged_gdf.columns:\n",
    "        print(\"Cannot create state-level map: Missing state/territory information\")  # 无法创建州级地图：缺少州/领地信息\n",
    "        return\n",
    "    \n",
    "    print(\"\\nCreating state/territory level election post heat map...\")  # 开始创建州/领地级别选举发帖热力图\n",
    "    \n",
    "    # Ensure geometries are valid\n",
    "    try:\n",
    "        # Check if geometries are valid and filter out empty geometries\n",
    "        print(\"Checking geometry validity...\")  # 检查几何形状有效性\n",
    "        valid_geoms = merged_gdf[~merged_gdf.geometry.is_empty]\n",
    "        if len(valid_geoms) < len(merged_gdf):\n",
    "            print(f\"Warning: Filtered out {len(merged_gdf) - len(valid_geoms)} empty geometries\")  # 警告: 过滤掉了空几何形状\n",
    "        \n",
    "        if len(valid_geoms) == 0:\n",
    "            print(\"Error: All geometries are empty, cannot create map\")  # 错误: 所有几何形状都是空的\n",
    "            return\n",
    "            \n",
    "        # Aggregate data by state/territory\n",
    "        # Use valid geometries, group by STATE_NAME and sum post_count\n",
    "        state_gdf = valid_geoms.dissolve(by='STATE_NAME', aggfunc={'post_count': 'sum'}).reset_index()\n",
    "        \n",
    "        # Confirm geometries are valid again\n",
    "        state_gdf = state_gdf[~state_gdf.geometry.is_empty]\n",
    "        \n",
    "        if len(state_gdf) == 0:\n",
    "            print(\"Error: All state/territory geometries are empty after grouping, cannot create map\")  # 错误: 分组后所有州/领地几何形状都是空的\n",
    "            return\n",
    "        \n",
    "        # Check if any states/territories are missing geometries\n",
    "        all_states = set(merged_gdf['STATE_NAME'].unique())\n",
    "        mapped_states = set(state_gdf['STATE_NAME'].unique())\n",
    "        missing_states = all_states - mapped_states\n",
    "        \n",
    "        if missing_states:\n",
    "            print(f\"Warning: The following states/territories are not included in the map due to geometry issues: {', '.join(missing_states)}\")  # 警告: 以下州/领地因几何形状问题未被包含在地图中\n",
    "        \n",
    "        # Prepare plot\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
    "        \n",
    "        # Calculate post count range\n",
    "        vmin = state_gdf['post_count'].min()\n",
    "        vmax = state_gdf['post_count'].max()\n",
    "        \n",
    "        # Create custom color map\n",
    "        cmap = LinearSegmentedColormap.from_list(\n",
    "            'state_cmap', ['#f7fbff', '#08519c'], N=256)\n",
    "        \n",
    "        # Use log scale\n",
    "        if vmin > 0:\n",
    "            norm = colors.LogNorm(vmin=vmin, vmax=max(vmax, vmin * 2))\n",
    "        else:\n",
    "            norm = colors.Normalize(vmin=0, vmax=vmax)\n",
    "        \n",
    "        # Draw map\n",
    "        state_gdf.plot(\n",
    "            column='post_count',\n",
    "            ax=ax,\n",
    "            cmap=cmap,\n",
    "            norm=norm,\n",
    "            edgecolor='black',\n",
    "            linewidth=0.8,\n",
    "            legend=True\n",
    "        )\n",
    "        \n",
    "        # Add state name labels - safely handle centroid calculation\n",
    "        for idx, row in state_gdf.iterrows():\n",
    "            try:\n",
    "                # Safely calculate centroid\n",
    "                geom = row.geometry\n",
    "                if geom is None or geom.is_empty:\n",
    "                    print(f\"Skipping label for empty geometry: {row['STATE_NAME']}\")  # 跳过空几何形状的标签\n",
    "                    continue\n",
    "                \n",
    "                # Try to calculate centroid, if fails use bounding box center\n",
    "                try:\n",
    "                    centroid = geom.centroid\n",
    "                    if centroid.is_empty:\n",
    "                        # Use bounding box center as alternative\n",
    "                        bounds = geom.bounds\n",
    "                        centroid_x = (bounds[0] + bounds[2]) / 2\n",
    "                        centroid_y = (bounds[1] + bounds[3]) / 2\n",
    "                    else:\n",
    "                        centroid_x = centroid.x\n",
    "                        centroid_y = centroid.y\n",
    "                except Exception as e:\n",
    "                    print(f\"Error calculating centroid for {row['STATE_NAME']}: {e}\")  # 计算质心时出错\n",
    "                    # Use bounding box center as alternative\n",
    "                    bounds = geom.bounds\n",
    "                    centroid_x = (bounds[0] + bounds[2]) / 2\n",
    "                    centroid_y = (bounds[1] + bounds[3]) / 2\n",
    "                \n",
    "                # Add label\n",
    "                ax.text(\n",
    "                    centroid_x, centroid_y, \n",
    "                    f\"{row['STATE_NAME']}\\n{int(row['post_count'])}\",\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                    fontsize=10,\n",
    "                    fontweight='bold',\n",
    "                    bbox=dict(facecolor='white', alpha=0.6, edgecolor='none', boxstyle='round,pad=0.3')\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error adding label for {row['STATE_NAME']}: {e}\")  # 添加标签时出错\n",
    "        \n",
    "        # Add color bar\n",
    "        sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "        sm.set_array([])\n",
    "        cbar = fig.colorbar(sm, ax=ax, shrink=0.7)\n",
    "        cbar.set_label('Election-related post count', fontsize=12)  # 选举相关发帖数量\n",
    "        \n",
    "        # Add title and annotations\n",
    "        plt.title('Australian States/Territories Election-related Post Heat Map', fontsize=16, pad=20)  # 澳大利亚各州/领地选举相关发帖热力图\n",
    "        plt.figtext(0.5, 0.01, 'Data source: Social media election analysis', ha='center', fontsize=10)  # 数据来源: 社交媒体选举分析\n",
    "        \n",
    "        # Remove axes\n",
    "        ax.set_axis_off()\n",
    "        \n",
    "        # Save image\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"Saved state-level map to {save_path}\")  # 已保存州级地图\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating state-level map: {e}\")  # 创建州级地图时出错\n",
    "        \n",
    "        # Create a simple bar chart as an alternative\n",
    "        try:\n",
    "            print(\"Attempting to create state-level bar chart as an alternative...\")  # 尝试创建州级柱状图作为替代\n",
    "            state_counts = merged_gdf.groupby('STATE_NAME')['post_count'].sum().sort_values(ascending=False)\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            state_counts.plot(kind='bar', color='steelblue')\n",
    "            plt.title('Australian States/Territories Election-related Post Count', fontsize=14)  # 澳大利亚各州/领地选举相关发帖数量\n",
    "            plt.xlabel('State/Territory', fontsize=12)  # 州/领地\n",
    "            plt.ylabel('Post Count', fontsize=12)  # 发帖数量\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save as alternative chart\n",
    "            alt_path = 'state_election_posts_chart.png'\n",
    "            plt.savefig(alt_path, dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "            print(f\"Created state-level bar chart as alternative: {alt_path}\")  # 已创建州级柱状图作为替代\n",
    "        except Exception as e2:\n",
    "            print(f\"Error creating alternative chart: {e2}\")  # 创建替代图表时也出错\n",
    "\n",
    "\n",
    "def create_state_level_map(merged_gdf, save_path='state_election_posts_map.png'):\n",
    "    \"\"\"Create state/territory level election post heat map\"\"\"\n",
    "    \n",
    "    if merged_gdf is None or 'STATE_NAME' not in merged_gdf.columns:\n",
    "        print(\"Cannot create state-level map: Missing state/territory information\")  # 无法创建州级地图：缺少州/领地信息\n",
    "        return\n",
    "    \n",
    "    print(\"\\nCreating state/territory level election post heat map...\")  # 开始创建州/领地级别选举发帖热力地图\n",
    "    \n",
    "    # Aggregate data by state/territory\n",
    "    state_gdf = merged_gdf.dissolve(by='STATE_NAME', aggfunc={'post_count': 'sum'}).reset_index()\n",
    "    \n",
    "    # Prepare plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(15, 12))\n",
    "    \n",
    "    # Calculate post count range\n",
    "    vmin = state_gdf['post_count'].min()\n",
    "    vmax = state_gdf['post_count'].max()\n",
    "    \n",
    "    # Create custom color map\n",
    "    cmap = LinearSegmentedColormap.from_list(\n",
    "        'state_cmap', ['#f7fbff', '#08519c'], N=256)\n",
    "    \n",
    "    # Use log scale\n",
    "    if vmin > 0:\n",
    "        norm = colors.LogNorm(vmin=vmin, vmax=max(vmax, vmin * 2))\n",
    "    else:\n",
    "        norm = colors.Normalize(vmin=0, vmax=vmax)\n",
    "    \n",
    "    # Draw map\n",
    "    state_gdf.plot(\n",
    "        column='post_count',\n",
    "        ax=ax,\n",
    "        cmap=cmap,\n",
    "        norm=norm,\n",
    "        edgecolor='black',\n",
    "        linewidth=0.8,\n",
    "        legend=True\n",
    "    )\n",
    "    \n",
    "    # Add state name labels\n",
    "    for idx, row in state_gdf.iterrows():\n",
    "        # Calculate centroid and add label\n",
    "        centroid = row.geometry.centroid\n",
    "        ax.text(\n",
    "            centroid.x, centroid.y, \n",
    "            f\"{row['STATE_NAME']}\\n{int(row['post_count'])}\",\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='center',\n",
    "            fontsize=10,\n",
    "            fontweight='bold',\n",
    "            bbox=dict(facecolor='white', alpha=0.6, edgecolor='none', boxstyle='round,pad=0.3')\n",
    "        )\n",
    "    \n",
    "    # Add color bar\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = fig.colorbar(sm, ax=ax, shrink=0.7)\n",
    "    cbar.set_label('Election-related post count', fontsize=12)  # 选举相关发帖数量\n",
    "    \n",
    "    # Add title and annotations\n",
    "    plt.title('Australian States/Territories Election-related Post Heat Map', fontsize=16, pad=20)  # 澳大利亚各州/领地选举相关发帖热力图\n",
    "    plt.figtext(0.5, 0.01, 'Data source: Social media election analysis', ha='center', fontsize=10)  # 数据来源: 社交媒体选举分析\n",
    "    \n",
    "    # Remove axes\n",
    "    ax.set_axis_off()\n",
    "    \n",
    "    # Save image\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Saved state-level map to {save_path}\")  # 已保存州级地图\n",
    "\n",
    "def generate_report(merged_gdf):\n",
    "    \"\"\"Generate SA3 region post analysis report\"\"\"\n",
    "    \n",
    "    if merged_gdf is None or merged_gdf.empty:\n",
    "        print(\"Cannot generate report: Insufficient data\")  # 无法生成报告：数据不足\n",
    "        return\n",
    "    \n",
    "    print(\"\\nGenerating SA3 region post analysis report...\")  # 生成SA3区域发帖分析报告\n",
    "    \n",
    "    # Create report file\n",
    "    report_path = 'sa3_election_report.txt'\n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(\"=======================================\\n\")\n",
    "        f.write(\"  Australian SA3 Region Election Post Analysis Report\\n\")  # 澳大利亚SA3区域选举发帖分析报告\n",
    "        f.write(\"=======================================\\n\\n\")\n",
    "        \n",
    "        # Overall statistics\n",
    "        f.write(\"1. Overall Statistics\\n\")  # 总体统计\n",
    "        f.write(\"--------------\\n\")\n",
    "        total_posts = merged_gdf['post_count'].sum()\n",
    "        active_regions = (merged_gdf['post_count'] > 0).sum()\n",
    "        \n",
    "        f.write(f\"Total posts: {total_posts}\\n\")  # 总发帖数\n",
    "        f.write(f\"SA3 regions with posts: {active_regions} (out of {len(merged_gdf)} regions)\\n\")  # 有发帖的SA3区域数\n",
    "        f.write(f\"SA3 regions without posts: {len(merged_gdf) - active_regions}\\n\\n\")  # 没有发帖的SA3区域数\n",
    "        \n",
    "        # Regions with most posts\n",
    "        f.write(\"2. SA3 Regions with Most Posts\\n\")  # 发帖最多的SA3区域\n",
    "        f.write(\"---------------------\\n\")\n",
    "        top_regions = merged_gdf.sort_values('post_count', ascending=False).head(20)\n",
    "        \n",
    "        for i, (_, row) in enumerate(top_regions.iterrows(), 1):\n",
    "            f.write(f\"{i}. {row['SA3_NAME']}: {int(row['post_count'])} posts\\n\")  # 帖子\n",
    "        \n",
    "        f.write(\"\\n\")\n",
    "        \n",
    "        # State/territory statistics (if state information available)\n",
    "        if 'STATE_NAME' in merged_gdf.columns:\n",
    "            f.write(\"3. State/Territory Statistics\\n\")  # 各州/领地统计\n",
    "            f.write(\"------------------\\n\")\n",
    "            \n",
    "            state_stats = merged_gdf.groupby('STATE_NAME')[['post_count']].agg(['sum', 'mean', 'count'])\n",
    "            state_stats.columns = state_stats.columns.droplevel()\n",
    "            state_stats = state_stats.sort_values('sum', ascending=False)\n",
    "            \n",
    "            for state, row in state_stats.iterrows():\n",
    "                total = int(row['sum'])\n",
    "                avg = row['mean']\n",
    "                count = int(row['count'])\n",
    "                active = merged_gdf[(merged_gdf['STATE_NAME'] == state) & (merged_gdf['post_count'] > 0)].shape[0]\n",
    "                \n",
    "                f.write(f\"{state}:\\n\")\n",
    "                f.write(f\"  - Total posts: {total}\\n\")  # 总发帖数\n",
    "                f.write(f\"  - Average posts per SA3 region: {avg:.1f}\\n\")  # 平均每个SA3区域发帖数\n",
    "                f.write(f\"  - Total SA3 regions: {count}\\n\")  # SA3区域总数\n",
    "                f.write(f\"  - SA3 regions with post activity: {active}\\n\")  # 有发帖活动的SA3区域数\n",
    "                f.write(f\"  - Percentage of total posts: {total/total_posts*100:.1f}%\\n\\n\")  # 占总发帖量百分比\n",
    "        \n",
    "        # Post count distribution\n",
    "        f.write(\"4. Post Count Distribution\\n\")  # 发帖数量分布\n",
    "        f.write(\"------------------\\n\")\n",
    "        \n",
    "        bins = [0, 1, 5, 10, 20, 50, 100, float('inf')]\n",
    "        labels = ['0', '1-4', '5-9', '10-19', '20-49', '50-99', '100+']\n",
    "        \n",
    "        post_dist = pd.cut(merged_gdf['post_count'], bins=bins, labels=labels).value_counts().sort_index()\n",
    "        \n",
    "        f.write(\"Post count range    SA3 regions    Percentage\\n\")  # 发帖数量范围    SA3区域数    百分比\n",
    "        f.write(\"-----------------------------------\\n\")\n",
    "        \n",
    "        for label, count in post_dist.items():\n",
    "            percentage = count / len(merged_gdf) * 100\n",
    "            f.write(f\"{label:<15} {count:<12} {percentage:.1f}%\\n\")\n",
    "    \n",
    "    print(f\"Report generated: {report_path}\")  # 已生成报告\n",
    "\n",
    "\n",
    "# === Start SA3 region election post map creation === #\n",
    "print(\"=== Starting SA3 region election post map creation ===\\n\")  # 开始SA3区域选举发帖地图创建\n",
    "\n",
    "# Load data\n",
    "gdf, location_counts = load_and_prepare_data()\n",
    "\n",
    "# Merge data\n",
    "merged_gdf = merge_data(gdf, location_counts)\n",
    "\n",
    "# Create maps\n",
    "create_sa3_choropleth(merged_gdf)\n",
    "\n",
    "# Create state-level map\n",
    "create_state_level_map(merged_gdf)\n",
    "\n",
    "# Generate report\n",
    "generate_report(merged_gdf)\n",
    "\n",
    "print(\"\\n=== SA3 region election post map creation completed ===\")  # SA3区域选举发帖地图创建完成"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
